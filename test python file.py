HW q values is het beste in send commands 

Best Q-values until now:
[[  8.87897069e+00   1.25762539e+00   4.93202556e-01]Xish
 [  4.92997229e+00   3.13791479e+00   1.31896801e+00]
 [ -3.11770312e-01  -2.94611891e-02   2.88232186e+00]
 [  8.19194429e+00   4.80088747e+00   2.34940829e+00]Xish
 [  1.62751718e+01   1.29316703e+00   2.29066616e-01]
 [  1.10349053e+01   3.64635964e+00   1.21293356e+00]X
 [  1.96034829e+01   2.04917471e+00   5.18751536e+00]
 [  1.71166964e+01   2.19189802e+00   7.05755446e-01]
 [  1.63188448e+01   1.33233714e+00   1.32481533e+00]
 [  6.81800266e-01   7.40693586e+00   2.23614145e+00]
 [  4.10152719e-01   7.99195128e+00   2.08699072e+00]
 [  3.02233084e+00   2.22489721e+00  -4.71877871e-03]]

Last Q-values:
[[  8.74993035e+00   1.25762539e+00   4.93202556e-01]
 [  1.29889851e+01   3.13791479e+00   1.73932885e+00]
 [ -3.11770312e-01  -2.94611891e-02   5.70552694e+00]
 [  1.63041599e+01   5.08098313e+00   3.55709725e+00]
 [  1.75796887e+01   1.29316703e+00   2.29066616e-01]
 [  1.35931858e+01   3.56231639e+00   3.38967689e+00]
 [  1.86072177e+01   2.04917471e+00   5.94638270e+00]
 [  1.94811863e+01   2.19189802e+00   7.05755446e-01]
 [  1.83009587e+01   1.53476693e+00   1.32481533e+00]
 [  1.31085243e+00   1.01708499e+01   2.23614145e+00]
 [  4.10152719e-01   1.15651655e+01   2.08699072e+00]
 [  8.27072402e+00   2.22489721e+00  -4.71877871e-03]]
^-> foraging run with markov from 23:28


Best Q-values until now:
[[ -0.10586074  -0.33961753   1.06267642]
 [  2.58748191  -0.36467384   0.10023623]
 [  1.00673487  -0.44121263   1.20667375]
 [  0.57851438   2.86755404   0.68258516]
 [  7.18924557  -0.50019435   0.22869919]
 [  8.59265379   0.74697811   1.51115747]
 [ 11.66818719   1.33254362   4.32211442]
 [  9.85766235   0.           0.        ]
 [ 10.79731793   1.55440648   2.44809888]
 [ -0.70776104  -0.10089384   3.67595418]]

Last Q-values:
[[  0.20477687   1.44648776   7.34966551]
 [ 10.48574272   1.39976751   1.8551617 ]
 [  1.28796034   1.55916041   6.84061933]
 [  4.87988315  10.30166788   2.57621054]
 [ 15.56866836   2.11489129   2.777154  ]
 [ 11.27029433   2.94104216   4.79392924]
 [ 16.81616381   1.66386557   4.32211442]
 [ 20.04200753   0.53523629   3.11806705]
 [ 21.03398905   1.55440648   5.39724592]
 [  4.42785156   6.62378114   3.18379169]]
^-> foraging run red from 22:40


["Top Left", "Top Center", "Top Right", "Middle Left", "Middle Center", "Middle Right", "Bottom Left", "Bottom Center", "Bottom Right", "No Food"]

--- {'episode_returns': [-100, 22, 68, -100, 61, 49, -100, 89, 96, -100, 21, -100, -100, 44, 87, 78, -100, 95, 62, -100, -100, -100, -100, 86, 59, 6, 79, 77, -100, 3, -100, 62, 54, 69, -100, 82, -100, 91, 47, 83, 93, 93, 82, 80, 87, 38, 81, 93, -100], 'episode_lengths': [100, 79, 33, 100, 40, 52, 100, 12, 5, 100, 80, 100, 100, 57, 14, 23, 100, 6, 39, 100, 100, 100, 100, 15, 42, 95, 22, 24, 100, 98, 100, 39, 47, 32, 100, 19, 100, 10, 54, 18, 8, 8, 19, 21, 14, 63, 20, 8, 100]} ---
Best Q-values until now:
[[ -2.71000000e-01  -4.18856311e-01  -1.90000000e-01]
 [ -4.74816410e-01  -3.12319000e-01  -3.04219000e-01]
 [ -5.71180627e-01  -4.43611900e-01  -4.74221881e-01]
 [ -4.87768354e-01   1.28056280e+00  -5.29267694e-01]
 [  2.97937228e-02   6.29923957e-01   4.18289770e-01]
 [ -6.21316633e-01  -3.04127951e-01   1.76670528e+00]
 [  3.22981600e+01   2.27640372e-01  -1.60214512e-01]
 [  0.00000000e+00   8.90000000e+00   0.00000000e+00]
 [ -1.94620249e-01  -3.92627140e-01  -5.13361000e-02]
 [ -3.11077990e+00  -5.38153372e-01  -3.03892909e+00]
 [ -1.03016790e+00  -9.92518878e-01  -1.16559180e+00]
 [ -8.03342961e-01  -8.29802991e-01  -7.43325498e-01]]

Last Q-values:
[[ -1.06901915e+00  -1.04576077e+00   1.62372165e+00]
 [ -1.25433782e-02  -1.38089087e+00  -1.44357196e+00]
 [ -1.16259401e+00  -1.22828826e+00  -7.29408544e-01]
 [ -1.51396944e+00   5.80530777e-01   9.90919820e+00]
 [  9.74047035e+00  -4.51083649e-01   3.19720974e-01]
 [ -1.11727197e+00  -1.23260588e+00   5.84445213e+00]
 [  4.58362515e+01   6.74068239e-01   3.41090530e+00]
 [  0.00000000e+00   3.32570351e+01   0.00000000e+00]
 [  3.57901882e+01  -6.81938698e-01   1.30426443e+01]
 [ -4.53489922e+00   1.39982524e+01  -3.54108126e+00]
 [  4.92078720e+00  -7.06181473e-01  -1.38823010e+00]
 [ -1.38800748e+00  -1.35245231e+00   5.24047343e+00]]

^-> 15:57 last runtime








x_prey = 1
x_pred = 1
y_prey = 1
y_pred = 1
x_prey1 = 1
y_prey1 = 1
if (abs(x_prey-x_pred) < 0.30 and abs(y_prey-y_pred) < 0.30) or (abs(x_prey1-x_pred) < 0.30 and abs(y_prey1-y_pred) < 0.30) and 5 > 0:
    print("hi")


# import matplotlib.pyplot as plt
# import numpy as np
# run1 = {'episode_returns': [-70, 21, 94, 67, -16, 21, -37, 87, 85, 63, 37, 67, 75, 121, 90, 73, 107, 104, 51, 91, 50, 83, 62, -47, 44, 21, 89, 65, 69, 17, 94, 68, 48, 124, 108, 99, -17, 127, -200, 119, 120, 107, 105, 92, 82, 84, 97, 91, 121, 59], 'episode_lengths': [201, 122, 102, 118, 200, 175, 200, 107, 100, 132, 138, 119, 122, 75, 107, 103, 89, 89, 143, 106, 135, 102, 133, 200, 121, 121, 97, 131, 128, 156, 81, 114, 147, 71, 88, 85, 200, 71, 200, 75, 76, 68, 91, 94, 102, 112, 90, 95, 76, 136]}
# run2 = {'episode_returns': [-124, 21, 106, 65, 88, 95, 117, 83, 89, 119, 124, 110, 106, 96, 68, 107, 92, 111, 98, 126, 36, 93, 92, 111, 94, 135, 114, 120, 93, 106, 99, 135, 143, 113, 131, 115, 41, 88, 93, 121, 128, 123, 114, 103, 127, 129, 110, 84, 111, 120],'episode_lengths': [200, 163, 79, 107, 110, 67, 78, 92, 83, 77, 71, 66, 90, 68, 128, 89, 104, 73, 66, 72, 117, 81, 82, 73, 56, 60, 81, 77, 70, 89, 85, 62, 54, 72, 62, 79, 134, 76, 79, 74, 46, 73, 81, 93, 67, 67, 88, 111, 74, 65]}
# run3 = {'episode_returns': [-26, 74, 116, 112, 126, 42, 119, 140, 127, 119, 121, 119, 110, 122, 89, 86, 115, 127, 121, -189, 51, 105, 122, 92, 74, 69, 118, 52, 91, 78, 129, 105, 91, 91, 87, -27, 100, 125, 48, 104, 125, 89, 104, 90, 37, 121, 136, -200, 129, 122],'episode_lengths': [200, 111, 79, 50, 69, 66, 78, 56, 55, 66, 72, 77, 64, 73, 97, 68, 69, 45, 62, 200, 123, 91, 65, 93, 122, 107, 65, 135, 105, 108, 65, 91, 95, 105, 111, 200, 85, 72, 148, 68, 72, 75, 93, 105, 104, 76, 59, 200, 55, 75]}
# returns = [-116, -102, -80, -38, 107, 110, 34, 109, -25, -37, -38, -38, 45, 1, 26, 90, 38, 60, 79, 81, 109, 66, 100, 92, 120, 7, -82, -80, 55, 80, 80, 46]
# plt.plot(run1["episode_lengths"])


    # def mask_img(self, img, rob_type="simulation"):
    #     if selection == "simulation":
    #         # Lower and upper boundary of green
    #         lower = np.array([0, 0, 0], np.uint8)
    #         upper = np.array([50, 255, 50], np.uint8)

    #         # Create a mask for orange
    #         mask = cv2.inRange(img, lower, upper)

    #     if selection == "hardware":
    #         hsv = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)
    #         minHSV = np.array([30, 0, 0])
    #         maxHSV = np.array([90, 255, 255])
    #         mask = cv2.inRange(hsv,minHSV,maxHSV)
    #     return mask

    # def get_state(self):
    #     #Subimages:
    #     #[0 1 2
    #     # 3 4 5
    #     # 6 7 8]

    #     img = self.rob.get_image_front()
    #     # img = rgb.copy()
    #     # gray = self.mask_img(rgb)

    #     # rows_rgb, cols_rgb, channels = rgb.shape
    #     # rows_gray, cols_gray = gray.shape

    #     # rows_comb = max(rows_rgb, rows_gray)
    #     # cols_comb = cols_rgb + cols_gray
    #     # comb = np.zeros(shape=(rows_comb, cols_comb, channels), dtype=np.uint8)

    #     # comb[:rows_rgb, :cols_rgb] = rgb
    #     # comb[:rows_gray, cols_rgb:] = gray[:, :, None]

    #     # try:
    #     #     cv2.imwrite("robotview.png", comb)
    #     # except:
    #     #     pass
    #     greencount = []
    #     for i in range(3):
    #         for j in range(3):
    #             part = len(img)/3
    #             sub_image = img[int(part*i):int(part*(i+1)), int(part*j):int(part*(j+1))]
    #             sub_image = self.mask_img(sub_image, rob_type)
    #             greencount.append(np.count_nonzero(sub_image))
    #     if sum(greencount) < 5:
    #         s = 9
    #     else:
    #         s = greencount.index(max(greencount))
    #     print("STATE: ", self.observation_labels[s])
    #     return s